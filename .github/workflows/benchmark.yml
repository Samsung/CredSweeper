# This workflow runs benchmark
# Separation of jobs helps to cache data even benchmark is fail

name: Benchmark

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #

  download_data:

    runs-on: ubuntu-latest

    steps:

    - name: Checkout CredData
      uses: actions/checkout@v3
      with:
        repository: Samsung/CredData

    - name: Cache data
      id: cache-data
      uses: actions/cache@v3
      with:
        path: data
        key: cred-data-${{ hashFiles('snapshot.yaml') }}

    - name: Set up Python 3.8
      if: steps.cache-data.outputs.cache-hit != 'true'
      uses: actions/setup-python@v3
      with:
        python-version: "3.8"

    - name: Update PIP
      run: python -m pip install --upgrade pip

    - name: Install requirements of CredData
      if: steps.cache-data.outputs.cache-hit != 'true'
      run: python -m pip install --requirement requirements.txt

    - name: Generate Data Asset
      if: steps.cache-data.outputs.cache-hit != 'true'
      run: python download_data.py --data_dir data

